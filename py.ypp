import pandas as pd
from lxml import etree

def strip_namespaces(xml_string):
    """Remove namespaces from the XML string."""
    parser = etree.XMLParser(ns_clean=True, recover=True, encoding='utf-8')
    tree = etree.fromstring(xml_string.encode('utf-8'), parser=parser)
    for elem in tree.iter():
        if elem.tag.startswith('{'):
            elem.tag = elem.tag.split('}', 1)[1]  # Strip namespace
    return tree

def extract_node_data(node, relevant_tags=None):
    """Extract text and attributes from a node with filtering."""
    extracted_data = {}

    # Extract node's text (if any) and attributes
    if node.text and node.text.strip():
        extracted_data[node.tag] = node.text.strip()

    # Extract attributes like type, version, etc.
    for attr_name, attr_value in node.attrib.items():
        extracted_data[f"{node.tag}_{attr_name}"] = attr_value

    # Only return relevant tags
    if relevant_tags is None or node.tag in relevant_tags:
        # Extract child nodes recursively only if relevant
        for child in node:
            child_data = extract_node_data(child, relevant_tags)
            extracted_data.update(child_data)

    return extracted_data

def extract_data(xml_string, custom_xpath=None):
    """Extract node data dynamically based on default and custom XPath."""
    try:
        # Parse XML and remove namespaces
        root = strip_namespaces(xml_string)

        # Default XPath to extract tradeId and related information
        default_xpath = './/tradeHeader/tradeId'
        default_nodes = root.xpath(default_xpath)

        # Prepare the data dictionary for this row (initially with tradeId values)
        row_data = {}

        # Extract tradeId-related data
        if default_nodes:
            for idx, node in enumerate(default_nodes, start=1):
                trade_id_data = extract_node_data(node)
                row_data.update(trade_id_data)

                # Extract alternateId if available
                for child in node:
                    if child.tag == 'alternateId':
                        child_data = extract_node_data(child)
                        row_data.update(child_data)

        # If a custom XPath is provided, extract that data too
        if custom_xpath:
            custom_nodes = root.xpath(custom_xpath)
            if custom_nodes:
                for node in custom_nodes:
                    # Check for 'swapStream' to handle streamIndex specifically
                    if node.tag == 'swapStream':
                        # Only extract streamIndex
                        if 'streamIndex' in node.attrib:
                            row_data['swapStream_index'] = node.attrib['streamIndex']
                    else:
                        # Extract any other relevant data for the provided path
                        custom_data = extract_node_data(node)
                        row_data.update(custom_data)

        return row_data

    except Exception as e:
        print(f"Error processing XML: {e}")
        return {}

def main():
    # Path to the CSV file containing XML data
    csv_file_path = "bcml_data.csv"  # Change to your actual CSV file path
    # Column in the CSV file that contains the XML strings
    xml_column = 'bcml'  # Change this to the name of your XML column

    # Input from the user for custom XPath (optional)
    xpath = input("Enter the XPath to extract (leave blank for just default tradeId): ")

    # Read the CSV file
    df = pd.read_csv(csv_file_path)

    # List to store all extracted data from the entire file
    all_extracted_data = []

    # Process each row and extract data based on the provided XPath
    for index, row in df.iterrows():
        xml_string = row[xml_column]
        extracted_values = extract_data(xml_string, xpath if xpath else None)

        # Add the row index for reference
        extracted_values['row_index'] = index

        # Append extracted values to the main list
        all_extracted_data.append(extracted_values)

    # Convert extracted data into a DataFrame
    if all_extracted_data:
        results_df = pd.DataFrame(all_extracted_data)
    else:
        results_df = pd.DataFrame(columns=["No Data Found"])

    # Output the results to a CSV file
    output_file = "extracted_values_output.csv"
    results_df.to_csv(output_file, index=False)
    print(f"Extracted data saved to {output_file}")

if __name__ == "__main__":
    main()
