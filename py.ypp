import pandas as pd
from lxml import etree

def strip_namespaces(xml_string):
    """Remove namespaces from the XML string."""
    parser = etree.XMLParser(ns_clean=True, recover=True, encoding='utf-8')
    tree = etree.fromstring(xml_string.encode('utf-8'), parser=parser)
    
    # Strip namespace prefixes from all elements
    for elem in tree.iter():
        if '}' in elem.tag:
            elem.tag = elem.tag.split('}', 1)[1]  # Remove namespace
    return tree

def extract_node_data(node):
    """Extract text and attributes from a node."""
    extracted_data = {}
    if node.text and node.text.strip():
        extracted_data[node.tag] = node.text.strip()  # Extract node's text
    
    # Extract attributes (like type, version, etc.)
    for attr_name, attr_value in node.attrib.items():
        extracted_data[f"{node.tag}_{attr_name}"] = attr_value
    return extracted_data

def extract_data(xml_string, custom_xpath=None):
    """Extract node data dynamically based on default and custom XPath."""
    try:
        # Parse XML and remove namespaces
        root = strip_namespaces(xml_string)

        # Prepare the data dictionary for this row
        row_data = {}

        # Default XPath to extract tradeId and related information
        default_xpath = './/tradeHeader/tradeId'
        default_nodes = root.xpath(default_xpath)

        # Extract tradeId-related data
        if default_nodes:
            for node in default_nodes:
                trade_id_data = extract_node_data(node)
                # Extract children of tradeId (if any, e.g., alternateId)
                for child in node:
                    child_data = extract_node_data(child)
                    trade_id_data.update(child_data)
                row_data.update(trade_id_data)
        else:
            print("No default nodes found for tradeId in XML.")  # Debug info

        # If a custom XPath is provided, extract that data too
        if custom_xpath:
            custom_nodes = root.xpath(custom_xpath)
            if custom_nodes:
                # Only take the first node from the custom_xpath results
                node = custom_nodes[0]
                custom_data = extract_node_data(node)
                # Extract any children of the custom node
                for child in node:
                    custom_child_data = extract_node_data(child)
                    custom_data.update(custom_child_data)
                # Merge custom XPath data with tradeId data in the same row
                row_data.update(custom_data)
            else:
                print(f"No nodes found for custom XPath: {custom_xpath}")  # Debug info

        # Log data for debugging
        if not row_data:
            print("Row data is empty for the current XML.")  # Debug info

        return row_data
    except Exception as e:
        print(f"Error processing XML: {e}")
        return {}

# Path to the CSV file containing XML data
csv_file_path = "test_aug4.csv"  # Adjust your actual CSV file path
xml_column = 'xmlstring'  # Change this to the name of your XML column

# Input from the user for custom XPath (optional)
xpath = input("Enter the XPath to extract (leave blank for just default tradeId): ")

# Read the CSV file
df = pd.read_csv(csv_file_path)

# List to store all extracted data from the entire file
all_extracted_data = []

# Process each row and extract data based on the provided XPath
for index, row in df.iterrows():
    xml_string = row[xml_column]
    extracted_values = extract_data(xml_string, xpath if xpath else None)
    # Add the row index for reference
    extracted_values['row_index'] = index
    # Append extracted values to the main list
    all_extracted_data.append(extracted_values)

# Convert extracted data into a DataFrame
if all_extracted_data:
    results_df = pd.DataFrame(all_extracted_data)
else:
    results_df = pd.DataFrame(columns=["No Data Found"])

# Output the results to a CSV file
output_file = "extracted.csv"
results_df.to_csv(output_file, index=False)
print(f"Extracted data saved to {output_file}")
